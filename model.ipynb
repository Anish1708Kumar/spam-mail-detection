{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a9edc8b",
   "metadata": {},
   "source": [
    "## **Initial Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "54db218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5e2941",
   "metadata": {},
   "source": [
    "Importing NLTK library and requirements for natural Language processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "772be5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\anish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\anish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\anish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e2e8cf",
   "metadata": {},
   "source": [
    "## **Loading DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "a91e57fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ham</td>\n",
       "      <td>Didn't you get hep b immunisation in nigeria.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3730</th>\n",
       "      <td>ham</td>\n",
       "      <td>Isn't frnd a necesity in life? imagine urself ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>ham</td>\n",
       "      <td>Height of Confidence: All the Aeronautics prof...</td>\n",
       "      <td>this wont even start........ Datz confidence..\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4020</th>\n",
       "      <td>ham</td>\n",
       "      <td>We have to pick rayan macleran there.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3009</th>\n",
       "      <td>ham</td>\n",
       "      <td>Imagine Life WITHOUT ME... see.. How fast u ar...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wen ur lovable bcums angry wid u, dnt take it ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       v1                                                 v2  \\\n",
       "46    ham      Didn't you get hep b immunisation in nigeria.   \n",
       "3730  ham  Isn't frnd a necesity in life? imagine urself ...   \n",
       "710   ham  Height of Confidence: All the Aeronautics prof...   \n",
       "4020  ham              We have to pick rayan macleran there.   \n",
       "3009  ham  Imagine Life WITHOUT ME... see.. How fast u ar...   \n",
       "1412  ham  Wen ur lovable bcums angry wid u, dnt take it ...   \n",
       "\n",
       "                                           Unnamed: 2 Unnamed: 3 Unnamed: 4  \n",
       "46                                                NaN        NaN        NaN  \n",
       "3730                                              NaN        NaN        NaN  \n",
       "710   this wont even start........ Datz confidence..\"        NaN        NaN  \n",
       "4020                                              NaN        NaN        NaN  \n",
       "3009                                              NaN        NaN        NaN  \n",
       "1412                                              NaN        NaN        NaN  "
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "df.sample(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e882f3d0",
   "metadata": {},
   "source": [
    "## **Data Cleaning**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "c1d28fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   v1          5572 non-null   object\n",
      " 1   v2          5572 non-null   object\n",
      " 2   Unnamed: 2  50 non-null     object\n",
      " 3   Unnamed: 3  12 non-null     object\n",
      " 4   Unnamed: 4  6 non-null      object\n",
      "dtypes: object(5)\n",
      "memory usage: 217.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c9bff1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the columns with manynull values as illustrated by the info()\n",
    "\n",
    "df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "9fca97f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the target variable from \"ham\" to 0 and \"spam\" to 1\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df['v1'] = encoder.fit_transform(df['v1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "2824bb34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for any duplicate values\n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "51ff02cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v1\n",
       "0    4516\n",
       "1     653\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping the duplicates and checking the distribution of DATA\n",
    "\n",
    "df = df.drop_duplicates(keep = 'first')\n",
    "df['v1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "81d2f74d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v1\n",
       "0    653\n",
       "1    653\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balancing the dataset as the number of ham messages is very large as compared to the number of spam messages\n",
    "\n",
    "spam = df[df['v1'] == 1]\n",
    "ham = df[df['v1'] == 0]\n",
    "\n",
    "ham_downsampled = resample(ham,replace=False, n_samples = len(spam),random_state=42)\n",
    "\n",
    "df = pd.concat([spam, ham_downsampled])\n",
    "\n",
    "# Suffling\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df['v1'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eae4f2a",
   "metadata": {},
   "source": [
    "Now the data is balanced and cleaned for further processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b159cf",
   "metadata": {},
   "source": [
    "## **DATA Preprocessing**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "999d8965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(text):\n",
    "    text = text.lower()\n",
    "    text = nltk.word_tokenize(text)\n",
    "\n",
    "\n",
    "    # Lower-casing\n",
    "    y = []\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "\n",
    "\n",
    "    # Removing special characters\n",
    "    for i in text:\n",
    "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "            y.append(i)\n",
    "\n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "\n",
    "\n",
    "    # Stemming\n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "\n",
    "    return \" \".join(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "ca2131d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the message coulmn of the dataset\n",
    "\n",
    "df[\"transformed_text\"] = df[\"v2\"].apply(transform_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "d451b9e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>transformed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>1</td>\n",
       "      <td>RT-KIng Pro Video Club&gt;&gt; Need help? info@ringt...</td>\n",
       "      <td>pro video club need help info call 08701237397...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>1</td>\n",
       "      <td>Gr8 new service - live sex video chat on your ...</td>\n",
       "      <td>gr8 new servic live sex video chat mob see sex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>swhrt how u dey,hope ur ok, tot about u 2day.l...</td>\n",
       "      <td>swhrt u dey hope ur ok tot u n care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>1</td>\n",
       "      <td>Bored of speed dating? Try SPEEDCHAT, txt SPEE...</td>\n",
       "      <td>bore speed date tri speedchat txt speedchat 80...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1</td>\n",
       "      <td>Free 1st week entry 2 TEXTPOD 4 a chance 2 win...</td>\n",
       "      <td>free 1st week entri 2 textpod 4 chanc 2 win 40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>1</td>\n",
       "      <td>URGENT! Your Mobile No. was awarded å£2000 Bon...</td>\n",
       "      <td>urgent mobil award bonu caller prize final tri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>0</td>\n",
       "      <td>Jane babes not goin 2 wrk, feel ill after lst ...</td>\n",
       "      <td>jane babe goin 2 wrk feel ill lst nite fone al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>0</td>\n",
       "      <td>They said if its gonna snow, it will start aro...</td>\n",
       "      <td>said gon na snow start around 8 9 pm tonit pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>Yup ok thanx...</td>\n",
       "      <td>yup ok thanx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>0</td>\n",
       "      <td>Haha... Yup hopefully  we will lose a few kg b...</td>\n",
       "      <td>haha yup hope lose kg mon hip hop go orchard w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      v1                                                 v2  \\\n",
       "206    1  RT-KIng Pro Video Club>> Need help? info@ringt...   \n",
       "550    1  Gr8 new service - live sex video chat on your ...   \n",
       "29     0  swhrt how u dey,hope ur ok, tot about u 2day.l...   \n",
       "563    1  Bored of speed dating? Try SPEEDCHAT, txt SPEE...   \n",
       "190    1  Free 1st week entry 2 TEXTPOD 4 a chance 2 win...   \n",
       "1264   1  URGENT! Your Mobile No. was awarded å£2000 Bon...   \n",
       "1025   0  Jane babes not goin 2 wrk, feel ill after lst ...   \n",
       "713    0  They said if its gonna snow, it will start aro...   \n",
       "63     0                                    Yup ok thanx...   \n",
       "824    0  Haha... Yup hopefully  we will lose a few kg b...   \n",
       "\n",
       "                                       transformed_text  \n",
       "206   pro video club need help info call 08701237397...  \n",
       "550   gr8 new servic live sex video chat mob see sex...  \n",
       "29                  swhrt u dey hope ur ok tot u n care  \n",
       "563   bore speed date tri speedchat txt speedchat 80...  \n",
       "190   free 1st week entri 2 textpod 4 chanc 2 win 40...  \n",
       "1264  urgent mobil award bonu caller prize final tri...  \n",
       "1025  jane babe goin 2 wrk feel ill lst nite fone al...  \n",
       "713   said gon na snow start around 8 9 pm tonit pre...  \n",
       "63                                         yup ok thanx  \n",
       "824   haha yup hope lose kg mon hip hop go orchard w...  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc662c7a",
   "metadata": {},
   "source": [
    "## **Converting text into numeric features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "6e8c6494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Tfidf \n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98026889",
   "metadata": {},
   "source": [
    "<!-- Naive bayes -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "2bd34422",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.fit_transform(df['transformed_text']).toarray()\n",
    "y = df['v1'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f0c23b",
   "metadata": {},
   "source": [
    "## **Train Test Splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "3a811903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ac3839",
   "metadata": {},
   "source": [
    "## **Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "a0e07370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am using Multinomial Naive-Bayes Model\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "model = mnb.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc009d7d",
   "metadata": {},
   "source": [
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "96105f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "d1f0d462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is :  0.9312977099236641\n",
      "Precision score of model is :  0.9242424242424242\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of the model is : \" , accuracy_score(y_test,y_pred))\n",
    "print(\"Precision score of model is : \", precision_score(y_test,y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ef356f",
   "metadata": {},
   "source": [
    "## **Checking the custom inputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "32c00dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(s):\n",
    "    x = transform_text(s)\n",
    "    vec = tf.transform([s])\n",
    "    return model.predict(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "19381809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spam\n"
     ]
    }
   ],
   "source": [
    "Example = input(\"Enter the SMS: \")\n",
    "\n",
    "if check(Example):\n",
    "    print(\"Spam\")\n",
    "else:\n",
    "    print(\"Not Spam\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
